from flask import Flask, render_template, request, jsonify
import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

app = Flask(__name__)

# –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
SHERLOCK_PROMPT = "–¢—ã - –®–µ—Ä–ª–æ–∫ –•–æ–ª–º—Å. –û—Ç–≤–µ—á–∞–π –≤ —Å—Ç–∏–ª–µ –¥–µ—Ç–µ–∫—Ç–∏–≤–∞."

scraped_content = []

def generate_response(question, context=""):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"""
    try:
        return generate_fallback_response(question, context)
    except Exception as e:
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."

def generate_fallback_response(question, context=""):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"""
    question_lower = question.lower()
    
    if any(word in question_lower for word in ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', 'hello']):
        return "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –Ø –®–µ—Ä–ª–æ–∫ –•–æ–ª–º—Å, –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –≤ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏."
    
    elif any(word in question_lower for word in ['–∫—Ç–æ —Ç—ã', '–ø—Ä–µ–¥—Å—Ç–∞–≤—å—Å—è']):
        return "–®–µ—Ä–ª–æ–∫ –•–æ–ª–º—Å, –¥–µ—Ç–µ–∫—Ç–∏–≤-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å –ë–µ–π–∫–µ—Ä-—Å—Ç—Ä–∏—Ç, 221–ë."
    
    elif any(word in question_lower for word in ['–ø–æ–º–æ—â—å', '—á—Ç–æ —É–º–µ–µ—à—å']):
        return "–î–µ–¥—É–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥, RAG —Å–∏—Å—Ç–µ–º–∞. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ URL –∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å!"
    
    elif any(word in question_lower for word in ['–∑–∞–≥–∞–¥–∫–∞', '–¥–µ–ª–æ', '–ø—Ä–æ–±–ª–µ–º–∞']):
        return "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏. –î–µ—Ç–∞–ª–∏ –∏–º–µ—é—Ç –∑–Ω–∞—á–µ–Ω–∏–µ."
    
    elif any(word in question_lower for word in ['–≤–∞—Ç—Å–æ–Ω', '–¥–æ–∫—Ç–æ—Ä']):
        return "–ú–æ–π –¥–æ—Ä–æ–≥–æ–π –í–∞—Ç—Å–æ–Ω - –≤–µ—Ä–Ω—ã–π –¥—Ä—É–≥ –∏ –ø–æ–º–æ—â–Ω–∏–∫."
    
    elif any(word in question_lower for word in ['–ª–æ–Ω–¥–æ–Ω', '–±–µ–π–∫–µ—Ä-—Å—Ç—Ä–∏—Ç']):
        return "–ë–µ–π–∫–µ—Ä-—Å—Ç—Ä–∏—Ç, 221–ë - –º–æ–π –¥–æ–º –∏ –æ—Ñ–∏—Å –≤ –õ–æ–Ω–¥–æ–Ω–µ."
    
    elif any(word in question_lower for word in ['—Å–∫—Ä–∏–ø–∫–∞', '–º—É–∑—ã–∫–∞']):
        return "–ú—É–∑—ã–∫–∞ –ø–æ–º–æ–≥–∞–µ—Ç –º–Ω–µ –¥—É–º–∞—Ç—å. –°–∫—Ä–∏–ø–∫–∞ - –º–æ–π —Å–ø—É—Ç–Ω–∏–∫ –≤ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è—Ö."
    
    elif context and len(context) > 10:
        return "–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω! –ì–æ—Ç–æ–≤ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã."
    
    else:
        responses = [
            "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ. –ú–æ–π –¥–µ–¥—É–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –≤ –¥–µ–π—Å—Ç–≤–∏–∏!",
            "–•–º, —ç—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –±–æ–ª—å—à–µ.",
            "–≠–ª–µ–º–µ–Ω—Ç–∞—Ä–Ω–æ! –•–æ—Ç—è, –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ —Å–æ–≤—Å–µ–º.",
            "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∑–∞–≥–∞–¥–∫–∞! –ú–æ–π —É–º —Ä–∞–±–æ—Ç–∞–µ—Ç.",
            "–ü–æ–∑–≤–æ–ª—å—Ç–µ –º–Ω–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ."
        ]
        import random
        return random.choice(responses)

def scrape_website(url):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–∏–Ω–≥"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return {
            'url': url,
            'title': soup.title.string if soup.title else url,
            'content': text[:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞: {e}")
        return None

def find_relevant_context(question, top_k=1):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    if not scraped_content:
        return ""
    
    try:
        question_lower = question.lower()
        relevant_chunks = []
        
        for content in scraped_content:
            content_lower = content['content'].lower()
            question_words = set(question_lower.split())
            content_words = set(content_lower.split())
            common_words = question_words.intersection(content_words)
            relevance_score = len(common_words) / len(question_words) if question_words else 0
            
            if relevance_score > 0.1:
                relevant_chunks.append((relevance_score, content['content'][:200]))
        
        relevant_chunks.sort(reverse=True)
        relevant_context = "\n".join([text for _, text in relevant_chunks[:top_k]])
        return relevant_context
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
        return ""

@app.route('/')
def index():
    return render_template('vercel_minimal.html')

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({'error': '–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'})
        
        context = find_relevant_context(message)
        response = generate_response(message, context)
        
        return jsonify({
            'response': response,
            'timestamp': datetime.now().strftime('%H:%M:%S')
        })
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á–∞—Ç–∞: {e}")
        return jsonify({'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞'})

@app.route('/scrape', methods=['POST'])
def scrape():
    try:
        data = request.get_json()
        url = data.get('url', '').strip()
        
        if not url:
            return jsonify({'error': 'URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'})
        
        scraped_data = scrape_website(url)
        
        if scraped_data:
            scraped_content.append(scraped_data)
            
            return jsonify({
                'success': True,
                'message': f'–°–∞–π—Ç {url} –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!',
                'title': scraped_data['title'],
                'timestamp': scraped_data['timestamp']
            })
        else:
            return jsonify({'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —É–∫–∞–∑–∞–Ω–Ω—ã–π URL'})
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞: {e}")
        return jsonify({'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ URL'})

@app.route('/status')
def status():
    return jsonify({
        'status': 'running',
        'model': 'Sherlock Holmes Minimal',
        'scraped_sites': len(scraped_content)
    })

if __name__ == '__main__':
    print("ü§ñ –ó–∞–ø—É—Å–∫ AI-–±–æ—Ç–∞ –®–µ—Ä–ª–æ–∫–∞ –•–æ–ª–º—Å–∞ (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)...")
    app.run(host='0.0.0.0', port=5000, debug=True) 